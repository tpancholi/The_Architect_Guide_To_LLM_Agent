{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Retrival logic discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:  # inside a script\n",
    "\tBASE_DIR = Path(__file__).resolve().parent.parent\n",
    "except NameError:  # inside a notebook\n",
    "\tBASE_DIR = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chunked and embedded text\n",
    "dataframe_path = pdf_path = BASE_DIR / \"data\" / \"text_chunk_and_embeddings_df.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading parquet file back for further processing\n",
    "text_chunks_and_embedding_df_load = pl.read_parquet(dataframe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and setup embedding model\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\", token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### let's write code for code similarity based on dot product, then sort the result based on similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"macronutrients functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = model.encode(query, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = text_chunks_and_embedding_df_load.describe()\n",
    "numeric_cols = [c for c, t in summary.schema.items() if t.is_numeric()]\n",
    "summary = summary.with_columns(\n",
    "\t[pl.col(c).round(2) if c in numeric_cols else pl.col(c) for c in summary.columns]\n",
    ")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = text_chunks_and_embedding_df_load[\"embedding\"].to_list()\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "print(\n",
    "\tf\"Time to get scores on {len(text_chunks_and_embedding_df_load['embedding'])} embeddings: {end_time - start_time} seconds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for printing\n",
    "import textwrap\n",
    "\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "\twrapped_text = textwrap.fill(text, wrap_length)\n",
    "\tprint(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Query: {query}\")\n",
    "print(\"Results: \\n\")\n",
    "for score, idx in zip(\n",
    "\ttop_results_dot_product[0].numpy(), top_results_dot_product[1].numpy()\n",
    "):\n",
    "\tprint(f\"Score: {score:.4f}\")\n",
    "\tprint(\"Text: \\n\")\n",
    "\tprint_wrapped(text_chunks_and_embedding_df_load[\"sentence_chunk\"][int(idx)])\n",
    "\tprint(f\"Page Number: {text_chunks_and_embedding_df_load['page_number'][int(idx)]}\")\n",
    "\tprint(\"\\n\" + \"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## the values are low here because we are using normalized vector which eliminates the magnitude part which is not used in cosine similarity score which but helps boost the score faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating final semantic search pipeline\n",
    "def retrieve_relevant_resources(\n",
    "\tquery: str,\n",
    "\tembeddings: list,\n",
    "\tmodel: SentenceTransformer,\n",
    "\tn_resources_to_return: int,\n",
    "\tprint_time: bool = True,\n",
    ") -> (torch.Tensor, torch.Tensor):\n",
    "\t\"\"\"Embeds the query and retrieves the top n_resources_to_return most relevant resources's score and index.\n",
    "\tArgs:\n",
    "\t    query (str): The query to search for.\n",
    "\t    embeddings (list): List of embeddings to search for the query in.\n",
    "\t    model (SentenceTransformer): The SentenceTransformer model to use for embedding.\n",
    "\t    n_resources_to_return (int): The number of resources to return.\n",
    "\t    print_time (bool): print the time taken to retrieve the resources.\n",
    "\tReturns:\n",
    "\t    None\n",
    "\t\"\"\"\n",
    "\tstart_time = timer()\n",
    "\tquery_embedding = model.encode(query, normalize_embeddings=True)\n",
    "\tdot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "\tscores, indices = torch.topk(dot_scores, k=n_resources_to_return)\n",
    "\tend_time = timer()\n",
    "\tif print_time:\n",
    "\t\tprint(\n",
    "\t\t\tf\"Time to get scores on {len(embeddings)} embeddings: {end_time - start_time} seconds.\"\n",
    "\t\t)\n",
    "\treturn scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_results_and_scores(\n",
    "\tquery: str,\n",
    "\tembeddings: list,\n",
    "\tpages_and_chunks: list[dict] = text_chunks_and_embedding_df_load,\n",
    "\tn_reources_to_return: int = 5,\n",
    "):\n",
    "\t\"\"\"This function prints the top n_reources_to_return most relevant resources's score and index.\"\"\"\n",
    "\tscores, indices = retrieve_relevant_resources(\n",
    "\t\tquery=query,\n",
    "\t\tembeddings=embeddings,\n",
    "\t\tmodel=model,\n",
    "\t\tn_resources_to_return=n_reources_to_return,\n",
    "\t)\n",
    "\tprint(f\"Query: {query}\")\n",
    "\tprint(\"Results: \\n\")\n",
    "\tfor score, idx in zip(scores.numpy(), indices.numpy()):\n",
    "\t\tprint(f\"Score: {score:.4f}\")\n",
    "\t\tprint(\"Text: \\n\")\n",
    "\t\tprint_wrapped(pages_and_chunks[\"sentence_chunk\"][int(idx)])\n",
    "\t\tprint(f\"Page Number: {pages_and_chunks['page_number'][int(idx)]}\")\n",
    "\t\tprint(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"symptoms of pellagra\"\n",
    "scores, indices = retrieve_relevant_resources(\n",
    "\tquery=query, embeddings=embeddings, model=model, n_resources_to_return=5\n",
    ")\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_results_and_scores(query=query, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
