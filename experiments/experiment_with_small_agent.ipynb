{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Evaluate Smolagent framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Ability\n",
    "- This agent will have access to web search via duckduckgo\n",
    "### Purpose\n",
    "- The task of agent is to provide you list of books for tech industry professionals on a given topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Model used\n",
    "- Qwen/Qwen2.5-Coder-32B-Instruct (default)\n",
    "- Qwen/Qwen3-Next-80B-A3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## first we would use codeAgent\n",
    "- codeAgent means the agent will try to write code and use the same to arrive at result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, InferenceClientModel\n",
    "\n",
    "agent = CodeAgent(\n",
    "\ttools=[DuckDuckGoSearchTool()],\n",
    "\tmodel=InferenceClientModel(\n",
    "\t\tapi_key=os.getenv(\"HF_WRITE_TOKEN\"),\n",
    "\t\tprovider=\"together\",\n",
    "\t\tmodel_id=\"Qwen/Qwen3-Next-80B-A3B-Instruct\",\n",
    "\t),\n",
    ")\n",
    "agent.run(\n",
    "\t\"Search for the best book recommendation for getting good at programming in rust for programmer who know python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\n",
    "\t\"I want to scale my production rag application, what is the best resource to learn and implement for my company.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_reg = CodeAgent(\n",
    "\ttools=[DuckDuckGoSearchTool()],\n",
    "\tmodel=InferenceClientModel(\n",
    "\t\tapi_key=os.getenv(\"HF_WRITE_TOKEN\"), provider=\"together\"\n",
    "\t),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_reg.run(\n",
    "\t\"Search for the best book recommendation for getting good at programming in rust for programmer who know python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_reg.run(\n",
    "\t\"I want to scale my production rag application, what is the best resource to learn and implement for my company.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Let's try the same with toolagent now\n",
    "- it will interact with `json` for input output and communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent, DuckDuckGoSearchTool, InferenceClientModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_agent_reg = ToolCallingAgent(\n",
    "\ttools=[DuckDuckGoSearchTool()],\n",
    "\tmodel=InferenceClientModel(\n",
    "\t\tprovider=\"together\", api_key=os.getenv(\"HF_WRITE_TOKEN\")\n",
    "\t),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_agent = ToolCallingAgent(\n",
    "\ttools=[DuckDuckGoSearchTool()],\n",
    "\tmodel=InferenceClientModel(\n",
    "\t\tprovider=\"together\",\n",
    "\t\tmodel_id=\"Qwen/Qwen3-Next-80B-A3B-Instruct\",\n",
    "\t\tapi_key=os.getenv(\"HF_WRITE_TOKEN\"),\n",
    "\t),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_agent_reg.run(\n",
    "\t\"I want to scale my production rag application, what is the best resource to learn and implement for my company.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_agent_reg.run(\n",
    "\t\"Search for the best book recommendation for getting good at programming in rust for programmer who know python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "|          Feature          | ToolCallingAgent              |              CodeAgent              |\n",
    "|:-------------------------:|-------------------------------|:-----------------------------------:|\n",
    "| **Complexity**            | Lower complexity              | Higher complexity                   |\n",
    "| **Flexibility**           | Structured and predictable    | Highly flexible and dynamic         |\n",
    "| **Arbitrary Code**        | No                            | Yes                                 |\n",
    "| **Typical tasks**         | Simple, structured tasks      | Complex, unstructured tasks         |\n",
    "| **Error risk**            | Lower (predictable execution) | Higher (can have runtime errors)    |\n",
    "| **3rd party packages**    | No                            | Can integrate to improve output     |\n",
    "| **Security implications** | Safer (API calls only)        | Needs caution(executes python code) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Let's integrate LangFuse and opentelemetry to see behind the scene in agent execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTEL_EXPORTER_OTLP_ENDPOINT = \"https://cloud.langfuse.com/api/public/otel\"  # EU Region\n",
    "# OTEL_EXPORTER_OTLP_ENDPOINT = \"https://us.cloud.langfuse.com/api/public/otel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(\n",
    "\tsecret_key=os.getenv(\"SECRET_KEY\"),\n",
    "\tpublic_key=os.getenv(\"PUBLIC_KEY\"),\n",
    "\thost=os.getenv(\"LANGFUSE_HOST\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "# Verify connection, do not use in production as this is a synchronous call\n",
    "if langfuse.auth_check():\n",
    "\tprint(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "\tprint(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_provider = TracerProvider()\n",
    "trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "SmolagentsInstrumentor().instrument(trace_provider=trace_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, InferenceClientModel\n",
    "\n",
    "agent_langfuse = CodeAgent(\n",
    "\ttools=[DuckDuckGoSearchTool()],\n",
    "\tmodel=InferenceClientModel(\n",
    "\t\tprovider=\"together\", api_key=os.getenv(\"HF_WRITE_TOKEN\")\n",
    "\t),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_langfuse.run(\n",
    "\t\"Search the best book for implementing agents for production using rust language.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent, InferenceClientModel\n",
    "\n",
    "tool_agent_langfuse = ToolCallingAgent(\n",
    "\ttools=[DuckDuckGoSearchTool()],\n",
    "\tmodel=InferenceClientModel(\n",
    "\t\tprovider=\"together\", api_key=os.getenv(\"HF_WRITE_TOKEN\")\n",
    "\t),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_agent_langfuse.run(\n",
    "\t\"Search the best book for implementing agents for production using rust language.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
