{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# LangGraph Agent with Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Use Case 2: Build a Vision Assistant Agent Using LangGraph\n",
    "### Goal\n",
    "- Build a vision assistant agent using LangGraph which looks at an image and provides information about the image.\n",
    "- Show case a method to integrate Thought-Observe-Action (TOA) like loop in LangGraph\n",
    "    - This is achieved by using Assistant Node calling Tool Node till certain conditions are met.\n",
    "        - Condition can be either a satisfactory response is achieved or a set number of iterations is reached. (max 10).  This is done to make sure we avoid infinite loops.\n",
    "    - The tool node can internally call n number of tools like query engine, web search tool, Arxiv search tool, coding agent, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "#### State\n",
    "- image\n",
    "#### Nodes\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Library used\n",
    "- langgraph\n",
    "- langchain_openai\n",
    "- langchain_core\n",
    "- langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get required environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"SECRET_KEY\")\n",
    "LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup langfuse client\n",
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(\n",
    "\tsecret_key=os.getenv(\"SECRET_KEY\"),\n",
    "\tpublic_key=os.getenv(\"PUBLIC_KEY\"),\n",
    "\thost=os.getenv(\"LANGFUSE_HOST\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "\tprint(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "\tprint(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize langfuse callback handler\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "langfuse_handler = CallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "vision_llm = ChatOpenAI(model=\"gpt-4.1-mini\", api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "# tool-1 : extract text from image\n",
    "def extract_text(img_path: Path) -> str:\n",
    "\t\"\"\"\n",
    "\tExtract text from an image file using a multimodel llm.\n",
    "\tArgs:\n",
    "\t\timg_path (Path): Path to the image file.\n",
    "\tReturns:\n",
    "\t\tA single string containing the extracted text concatenated from all images present at the path.\n",
    "\t\"\"\"\n",
    "\tall_text = \"\"\n",
    "\ttry:\n",
    "\t\tif isinstance(img_path, str):\n",
    "\t\t\timg_path = Path(img_path)\n",
    "\t\t# read image file\n",
    "\t\twith img_path.open(\"rb\") as img_file:\n",
    "\t\t\timage_bytes = img_file.read()\n",
    "\t\timage_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\t\t# prepare the message array to mimic human interaction\n",
    "\t\tmessage = [\n",
    "\t\t\tHumanMessage(\n",
    "\t\t\t\tcontent=[\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\t\t\"text\": (\n",
    "\t\t\t\t\t\t\t\"Extract all the text from this image. \"\n",
    "\t\t\t\t\t\t\t\"Return only the extracted text, no explanations.\"\n",
    "\t\t\t\t\t\t),\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\t\t\"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"},\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t]\n",
    "\t\t\t)\n",
    "\t\t]\n",
    "\t\t# call the vision model\n",
    "\t\tresponse = vision_llm.invoke(message)\n",
    "\t\t# append extracted text\n",
    "\t\tall_text += response.content + \"\\n\\n\"\n",
    "\t\treturn all_text.strip()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error extracting text from image: {str(e)}\")\n",
    "\t\treturn \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### We would add a random tool for explanation purpose for a use case where multiple tool might be required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool - 2 divide tool\n",
    "def divide_numbers(a: int, b: int) -> float:\n",
    "\t\"\"\"Divides two numbers a and b and returns the result.\n",
    "\tArgs:\n",
    "\t    a (int): The first number.\n",
    "\t    b (int): The second number.\n",
    "\tReturns:\n",
    "\t    float: The result of a / b.\n",
    "\t\"\"\"\n",
    "\treturn a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [divide_numbers, extract_text]\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", api_key=OPENAI_API_KEY)\n",
    "llm_with_tools = llm.bind_tools(tools=tools_list, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Let's design the agent to have our desired behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Optional\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "\tinput_file: Optional[Path]\n",
    "\tmessages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state: AgentState):\n",
    "\tdescription_of_tool = \"\"\"\n",
    "extract_text(img_path:Path) -> str:\n",
    "    Extract text from an image file using a multimodel llm.\n",
    "    Args:\n",
    "    \timg_path (Path): Path to the image file.\n",
    "    Returns:\n",
    "    \tA single string containing the extracted text concatenated from all images present at the path.\n",
    "divide_numbers(a: int, b: int) -> float\n",
    "    Divides two numbers a and b and returns the result.\n",
    "    \"\"\"\n",
    "\timage = state[\"input_file\"]\n",
    "\tif image:\n",
    "\t\tsys_msg = SystemMessage(\n",
    "\t\t\tcontent=f\"\"\"You are a helpful agent that can analyse images and run computations.\n",
    "                Available tools:\n",
    "                {description_of_tool}\n",
    "\n",
    "                An image has been loaded and is available at this path: {image}\n",
    "\n",
    "                When you need to extract text from the image, use the extract_text tool with the exact path: {image}\n",
    "                \"\"\"\n",
    "\t\t)\n",
    "\telse:\n",
    "\t\tsys_msg = SystemMessage(\n",
    "\t\t\tcontent=f\"\"\"You are a helpful agent that can analyse images and run computations.\n",
    "        Available tools:\n",
    "{description_of_tool}\n",
    "\n",
    "No image is currently loaded in the state.\n",
    "\"\"\"\n",
    "\t\t)\n",
    "\treturn {\n",
    "\t\t\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])],\n",
    "\t\t\"input_file\": image,\n",
    "\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Explanation on next steps\n",
    "- `assistant` node is just our model with bound tools\n",
    "- we would add `tool_condition` which will help route between `END` or `Tools` based on whether the `assistant` calls a tool.\n",
    "- Now we connect nodes and edges to form a loop in graph.\n",
    "    - After the `assistant` node executes, `tools_condition` checks if the model's output is satisfactory or not.\n",
    "    - If the tool call is required `tool_node` is called.\n",
    "    - `tool_node` is called till the output is satisfactory.\n",
    "    - if the model response is not a tool call, then `END` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# define nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools=tools_list))\n",
    "\n",
    "# define edge\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "\t\"assistant\",\n",
    "\ttools_condition,\n",
    "\t# if the latest message (result) from assistant is a tool call -> tool_condition routes to tools\n",
    "\t# if the latest message (result) from assistant is not a tool call -> tools_condition routes to END\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# show the graph\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {
    "6b5620d6-8132-4bb1-ba09-761650afc260.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "![image.png](attachment:6b5620d6-8132-4bb1-ba09-761650afc260.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Divide 324 by 4\")]\n",
    "messages = react_graph.invoke(\n",
    "\t{\"messages\": messages, \"input_file\": None}, config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in messages[\"messages\"]:\n",
    "\tm.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### Now let's test with image extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:  # inside a script\n",
    "\tBASE_DIR = Path(__file__).resolve().parent.parent\n",
    "except NameError:  # inside a notebook\n",
    "\tBASE_DIR = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Project root set to: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_menu_path = BASE_DIR / \"data\" / \"batman_diet_menu.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup initial message\n",
    "messages = [\n",
    "\tHumanMessage(\n",
    "\t\tcontent=\"According to the note provided by Mr. Wayne in the images.  What's the list of items I should by for the dinner menu?\"\n",
    "\t)\n",
    "]\n",
    "# invoke graph with new message\n",
    "messages = react_graph.invoke(\n",
    "\t{\"messages\": messages, \"input_file\": Path(diet_menu_path)},\n",
    "\tconfig={\"callbacks\": [langfuse_handler]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in messages[\"messages\"]:\n",
    "\tm.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "#### Note\n",
    "- I tried using different model from gpt-4o, gpt-4.1, gpt-4.1-mini, gpt-5-mini.\n",
    "    - I got best result with gpt-5-mini but latency was high(~3x).\n",
    "    - gpt-4.1-mini and gpt-4.1 result were almost identical but gpt-4.1-mini was faster(50% faster).\n",
    "    - gpt-4o result was not as good as gpt-4.1-* but latency was similiar to gpt-4.1-mini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's showcase if we can get the loop to work\n",
    "# setup initial message\n",
    "messages = [\n",
    "\tHumanMessage(\n",
    "\t\tcontent=\"According to the note provided by Mr. Wayne in the images.  What's the list of items I should by for the dinner menu?  Count the number of items and divide them by 50.  Give resulting answer.  Do not stop untill you have integer answer.\"\n",
    "\t)\n",
    "]\n",
    "# invoke graph with new message\n",
    "messages = react_graph.invoke(\n",
    "\t{\"messages\": messages, \"input_file\": Path(diet_menu_path)},\n",
    "\tconfig={\"callbacks\": [langfuse_handler]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in messages[\"messages\"]:\n",
    "\tm.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's showcase if we can get the loop to work\n",
    "# setup initial message\n",
    "messages = [\n",
    "\tHumanMessage(\n",
    "\t\tcontent=\"According to the note provided by Mr. Wayne in the images.  What's the list of items I should by for the dinner menu?  Then send an email to the recipient email with list of items.\"\n",
    "\t)\n",
    "]\n",
    "# invoke graph with new message\n",
    "messages = react_graph.invoke(\n",
    "\t{\"messages\": messages, \"input_file\": Path(diet_menu_path)},\n",
    "\tconfig={\"callbacks\": [langfuse_handler]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in messages[\"messages\"]:\n",
    "\tm.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
