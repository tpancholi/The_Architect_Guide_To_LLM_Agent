{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the below dependencies\n",
    "# !pip install python-dotenv smolagents[telemetry] langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-smolagents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### pre-requisite\n",
    "- API Keys for\n",
    "\t- Hugging Face (Hugging Face write token)\n",
    "\t- Langfuse (secret key, public key, host url)\n",
    "- Access to Qwen3 or similar Model on the hugging face platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variables to get api keys and other secrets\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup langfuse client\n",
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(\n",
    "\tsecret_key=os.getenv(\"SECRET_KEY\"),\n",
    "\tpublic_key=os.getenv(\"PUBLIC_KEY\"),\n",
    "\thost=os.getenv(\"LANGFUSE_HOST\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate langfuse client connection\n",
    "from langfuse import get_client\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "# Verify connection, do not use in production as this is a synchronous call\n",
    "if langfuse.auth_check():\n",
    "\tprint(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "\tprint(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up opentelemetry with langfuse for tracing information\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up opentelemetry tracer\n",
    "trace_provider = TracerProvider()\n",
    "trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up smolagents instrumentor\n",
    "SmolagentsInstrumentor().instrument(trace_provider=trace_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup smolagents agent as Code Agent\n",
    "from smolagents import CodeAgent, InferenceClientModel, DuckDuckGoSearchTool\n",
    "\n",
    "agent_langfuse = CodeAgent(\n",
    "\ttools=[DuckDuckGoSearchTool()],\n",
    "\tmodel=InferenceClientModel(\n",
    "\t\tmodel_id=\"Qwen/Qwen3-Next-80B-A3B-Instruct\",  # mention the LLM model id here\n",
    "\t\tprovider=\"together\",\n",
    "\t\tapi_key=os.getenv(\"HF_WRITE_TOKEN\"),  # change provider based on your preference\n",
    "\t),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt for the agent to get learning material for the user and format in the markdown table format\n",
    "agent_langfuse.run(\n",
    "\t\"\"\"\n",
    "\tYou are a helpful assistant that recommends books for learning technical topics.\n",
    "You have access to a search tool called {search_tool}. Use it to find books.\n",
    "\n",
    "**Step 1:** Use DuckDuckGo to search the web for books relevant to the user's query.\n",
    "**Step 2:** Parse the search results and filter out nonâ€‘books (articles, blogs, etc.).\n",
    "**Step 3:** Rank the books by relevance and publication year.\n",
    "**Step 4:** Return a markdown table with columns: Rank, Title, Author, Year, URL.\n",
    "User's query: please search for materials about creating production ready agentic rag using rust or go language.\n",
    "\t\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
